Following the first part, Tim focused on how human being is affected by friendly or unfriendly ASI, and asserted the eventual result is either immorality or extinction. Although I doubt his over-optimistic attitude towards the possibility of ASI, I appreciate his idea that people “make the mistake of anthropomorphizing AI” by assuming all high-level intelligences think in the same way human. However, the high-level emotions like empathy for human seems more like an intuition instead of an inherently programmed module. Also, another persuasive example is that human nature may result drastic change of decision making at moments, which is hard to be imitated by AI’s continuing regression. Therefore, we shall recognize human ethics is not a necessity of high-level intelligence, and when AI is powerful and intelligent enough, it may ignore human ethics to pursue its objective, and if the AI has evolved to ASI, like the game “Make A Paperclip” or the story of Turry, it may destroy anything for escalating it original harmless objective. To prevent this kind of hazard, a rational expediency is to restrain ASI ’s capability to make it a super intelligent thinker, while leaving human and ANI to be actors.
