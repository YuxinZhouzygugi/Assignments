From this second part of the reading there are really three points that stood out to me, specifically around thinking about what an AI super-intelligence could resemble. It’s interesting to note the idea that when we talk about potential AIs, and their motivations, and morals, doing so is anthropomorphizing them in our attempt to make sense of something potentially incomprehensible to us. We attach recognizable morals to a potential AI in order to make sense of it. 

I like the comparison that the article then lays out, between the consciousness of an ant and that of a person. An ant simply lacks the same mental structures that enable the thought processes and mental functions that humans posses. In that sense, what people do doesn’t only not make sense to an ant, but it is incomprehensible. I hadn’t thought about A1 like this before—that if it so advanced in its cognitive capabilities, that its thinking is of a higher order that simply can’t be related to human—the idea of amorality. 


