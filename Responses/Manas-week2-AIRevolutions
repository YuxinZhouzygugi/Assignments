I liked how Tim Urban started his entire article by first explaining the Law of Accelerating returns. He knew how implausible some of his ideas might seem so he established the fact that everything he was writing had a strong foundation in reality and that he was not just talking about the plot of a Sci-fi film.
Speaking of Sci-fi, in the second article the author talked about how movies have totally distorted our idea of AI and how we perceive them to be. I completely agree with him and I too have been influenced by representations of AI in popular culture. My idea of AI was something similar to VIKI from the movie iRobot. Now, with the information that the author gives about the three different kinds of AI and the example of Turry (the note writing bot/AI that took over the galaxy), I have a lot more clarity about what AI is and what it can do.
For me the most interesting parts of the article were about the fact that we cannot even comprehend the level of intelligence of an ASI and the challenge of avoiding anthropomorphizing. Based on all the information that I gathered from the article, I find myself leaning towards the ‘Anxious Avenue’ camp. I am fully aware of the potential life changing benefits of an ASI but I just don’t think that it is worth the risk. The moment of hitting the ‘tripwire’ will leave us totally unsure of our own existence: Immorality or extinction. I don’t think any level of progress can justify this risk to be taken.
