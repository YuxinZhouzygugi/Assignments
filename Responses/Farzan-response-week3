The analogy of AI and human intelligence to that of the ant and human intelligence really helps llustrate the magnitude of the differences that are present on every level of the two structures. Using the term 'superintelligence' for it makes it seem both scarier and more real in terms of its consequences and magnitude of unpredictability attached to it. I think if looked at as a whole, the two articles setup the stage really well with the first one explaining the fundamentals, while the second one making sure that the reader realises the magnitude of the situation. The theory that the more intelligent a machine gets, the faster it will be able to progress after realising its intelligence makes me think of a an endless loop that feeds back into itself and is almost self-sustaining. Its lack of dependency on other things is what makes it alarming in a way. 
